version: '3.8'

services:
  elasticsearch:
    container_name: elasticsearch
    image: elasticsearch:8.15.2
    ports:
      - "9200:9200"
      - "9300:9300"
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
      - logger.level=warn
    healthcheck:
      test: ["CMD", "curl", "-f", "http://elasticsearch:9200"]
      interval: 20s
      timeout: 10s
      retries: 5
    networks:
      - mynetwork
    volumes:
      - elasticsearch_data:/usr/share/elasticsearch/data

  scraping:
    container_name: scraping
    build:
      context: ./gaultmillau_scraper
    depends_on:
      elasticsearch:
        condition: service_healthy
    networks:
      - mynetwork
    command: >
      sh -c "
      if curl -s http://elasticsearch:9200/gaultmillau_restaurants | grep 'index_not_found_exception'; 
      then scrapy crawl gaultmillau; 
      else echo 'Data already present in Elasticsearch, skipping scraping'; 
      fi"
    restart: "no"

  flask:
    container_name: flask
    build:
      context: ./Api_WEB  # Dossier contenant le code Flask (à adapter si nécessaire)
    depends_on:
      scraping:
        condition: service_completed_successfully  # Démarre une fois le scraping terminé
    ports:
      - "5000:5000"
    networks:
      - mynetwork
    environment:
      - ELASTICSEARCH_HOST=http://elasticsearch:9200
      - FLASK_APP=FlaskApp/app.py
      - FLASK_ENV=development
    command: ["flask", "run", "--host=0.0.0.0", "--port=5000"]

networks:
  mynetwork:
    driver: bridge

volumes:
  elasticsearch_data:
