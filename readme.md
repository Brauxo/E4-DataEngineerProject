![Static Badge](https://img.shields.io/badge/ESIEE%20Paris%20-%20Projet%20E4%20-%20green?style=flat)
![Static Badge](https://img.shields.io/badge/last%20commit%20-%20November%202024%20-%20blue)
<div align="center">
<img src="https://github.com/user-attachments/assets/78cac6dc-d058-4576-8eef-572581c74311" width="65%"/>
</div>
<a id="readme-top"></a>

# Description

Ce projet vise √† extraire des donn√©es depuis le site 'gaultmillau.com', les stocker dans une base de donn√©es Elasticsearch, et les rendre consultables √† travers une application Web cr√©√©e avec Flask.
Pour offrir une exp√©rience utilisateur fluide, nous avons utilis√© Elasticsearch pour optimiser les capacit√©s de recherche et con√ßu une interface interactive en combinant CSS et JavaScript. Le projet s‚Äôappuie sur Docker pour simplifier le d√©ploiement, automatiser l‚Äôex√©cution des diff√©rentes √©tapes (scraping, stockage, service Web) et garantir une reproductibilit√© optimale sur diff√©rents environnements.

<a id="readme-top"></a>
# Sommaire

## Guide de l'utilisateur
1. [Pr√©requis d'installation](#1---Pr√©requis-dinstallation)
2. [Installation](#2---Installation)
3. [Lancer le projet](#3---Lancer-le-projet)
4. [Les diff√©rentes pages](#4---Les-differentes-pages)

## Guide du D√©veloppeur
1. [Aper√ßu global du projet](#1---Aper√ßu-global-du-projet)
2. [Scraping](#2---Scraping)
3. [API Web](#3---API-Web)
4. [Architecture et technologies utilis√©es](#4---Architecture-et-technologies-utilis√©es)

## Pour aller plus loin
1. [Id√©es d'am√©liorations](#1---Id√©es-dam√©liorations)
2. [D√©fis rencontr√©s](#2---D√©fis-rencontr√©s)
3. [Bugs connus](#3---Bugs-connus)


# Guide de l'utilisateur

## 1 - Pr√©requis d'installation

Dans un premier temps, regardons ce que vous devez installer pour r√©cup√©rer et utiliser le projet.

Deux outils sont n√©cessaires :

[Git](https://github.com/cambierelliot/E4-DataEngineerProject) pour cloner le projet depuis le d√©p√¥t opensource GitHub.

[DockerDesktop](https://www.docker.com/products/docker-desktop/) pour faire fonctionner le projet.

Faites une installation classique de docker.

## 2 - Installation

Dans cette partie, nous allons importer le projet disponible sur GitHub afin de l‚Äôavoir sur votre machine (en local).

Pour ce faire, ouvrez le Git Bash ou tout autre terminal et rendez-vous dans le dossier o√π vous d√©sirez stocker le projet gr√¢ce √† la commande :
```
   $ cd <r√©pertoire d√©sir√©>/
```
Lorsque vous √™tes dans le dossier voulu, rentrez la commande suivante :
```
   $ git clone https://github.com/cambiere/E4-DataEngineerProject
```
‚ö† Attendez l'importation totale du projet

## 3 - Lancer le projet

Commencez par rejoindre le dossier du projet :

```
   $ cd E4-DataEngineerProject/
```
Une fois que vous √™tes bien dans ce r√©pertoire, veuillez lancer l'application docker (e.g. DockerDesktop sur Windows). Elle doit √™tre en fonctionnement pour continuer.

Pour ex√©cuter le projet, il suffit de rentrer la commande suivante
```
$ docker compose up -d
```


Patientez jusqu'√† l'apparition d'un groupe de conteneurs dans votre application Docker. Cela peut prendre quelques minutes, car le processus de scraping est en cours. Un volume est √©galement cr√©√© pour les lancements ult√©rieurs : le scraping ne sera alors plus n√©cessaire, et les donn√©es locales seront utilis√©es.

‚ö† Veillez √† ne pas arr√™ter les services pour le bon fonctionnement de l'application Web.

Une fois le service flask en vert, vous pouvez cliquer sur le port surlign√© en jaune 5000 :5000 (voir image ci-dessous) ou bien cliquer ici : http://localhost:5000/
![image](https://github.com/user-attachments/assets/aa1cdcf7-a114-42f7-8e11-be71561aa07e)

<p align="center">(<a href="#readme-top">Haut de la page</a>)</p>

## 4 - Les diff√©rentes pages

<div align="center">
<h3>Page d'accueil du site</h3>
</div>

![home](img/home.gif)

La page d'accueil du site pr√©sente un design √©l√©gant et intuitif, permettant aux utilisateurs de rechercher et d√©couvrir des restaurants selon leurs pr√©f√©rences. Voici les principales caract√©ristiques de cette page :

#### Barre de recherche personnalis√©e
- Trois menus d√©roulants pour affiner les crit√®res de recherche :
  - **D√©partement** : Permet de s√©lectionner une r√©gion g√©ographique.
  - **Type de cuisine** : Offre des options comme "Fran√ßais", "Italien", "Japonais", etc.
  - **Note minimale** : Permet de filtrer les restaurants en fonction de leur score.
- Un bouton **"Rechercher"** pour effectuer la recherche selon les crit√®res s√©lectionn√©s.

#### Navigation rapide par types de cuisine
- Une section en dessous de la barre de recherche met en avant **6 types de cuisine populaires**.
- Chaque cat√©gorie est **cliquable** et redirige l'utilisateur vers une page d√©di√©e pour explorer des restaurants sp√©cifiques.

#### Header interactif
- Un header fixe contenant des liens vers les sections principales du site :
  - **Les restaurants**
  - **Analyse**
  - **√Ä propos de nous**
- Le header dispara√Æt automatiquement lors du d√©filement vers le bas pour laisser plus d'espace √† l'utilisateur et r√©appara√Æt en haut.

#### Footer informatif
- Le footer inclut des liens suppl√©mentaires, des informations sur les auteurs du projet et un design sobre pour cl√¥turer la page.

<div align="center">
<h3> Page exploration restaurant </h3>
</div>

<div align="center">
<h3> Page d'analyse </h3>
</div>

<div align="center">
<h3> Page a propos de nous </h3>
</div>

![home](img/about.gif)
La page "√Ä propos de nous" pr√©sente les contributeurs principaux du projet avec leurs profils respectifs et les outils utilis√©s dans le d√©veloppement du site.

- **Pr√©sentation des contributeurs** : Chaque contributeur est affich√© avec une photo, un descriptif de son parcours, et ses domaines d'expertise.
- **Contact direct** : Les adresses email des contributeurs sont fournies pour toute communication.
- **Technologies utilis√©es** : Une section en bas met en avant les principaux outils et technologies comme Elasticsearch, Docker, Scrapy, GitHub, et Flask.

<p align="center">(<a href="#readme-top">Haut de la page</a>)</p>

# Guide du D√©veloppeur

## 1 - Aper√ßu global
Le projet propose une solution int√©gr√©e permettant de scrapper les donn√©es de restaurants depuis **Gault & Millau**, de les stocker dans **Elasticsearch**, et de les rendre accessibles via une application web construite avec **Flask**. L'architecture repose sur Docker pour assurer un d√©ploiement reproductible.

## 2 - Scrapping
Le scrapping utilise **Python** et des biblioth√®ques telles que **BeautifulSoup** pour analyser les pages HTML et **Requests** pour l‚Äôenvoi des requ√™tes. Le processus extrait :
- Noms des restaurants.
- Adresses et coordonn√©es GPS.
- Sp√©cialit√©s culinaires.
- Notes.

Les donn√©es structur√©es sont import√©es dans Elasticsearch en tant qu'index.

## 3 - API Web
Le backend, bas√© sur **Flask**, offre des endpoints pour :
- Afficher la liste des restaurants.
- Obtenir des d√©tails sp√©cifiques √† un restaurant.
- Rechercher par mot-cl√© ou crit√®res (ex. sp√©cialit√©, localisation).

## 4 - Architecture et technologies utilis√©es
- **Backend** : Python, Flask.
- **Scraping** : BeautifulSoup, Requests.
- **Base de donn√©es** : Elasticsearch.
- **Frontend** : HTML/CSS/JS.
- **D√©ploiement** : Docker Compose.

![img.png](img/img.png) 

<p align="center">(<a href="#readme-top">Haut de la page</a>)</p>

# Pour aller plus loin

## 1 - Id√©es d'am√©liorations
- Ajouter des **filtres dynamiques** (par budget, distance).
- Int√©grer une **interface mobile-friendly** ou cr√©er une app mobile.
- Mettre en place une **API REST avanc√©e** pour d‚Äôautres types de clients (apps tierces).

## 2 - D√©fis rencontr√©s
- Contournement des **limitations des sites web** (CAPTCHA, restrictions IP).
- Optimisation des requ√™tes Elasticsearch.
- Assurer une **compatibilit√© front-end** entre navigateurs.

## 3 - Bugs connus
- [en partie r√©solu] Il se peut qu'une des pages du site de gault et millau soit down et que le scrapping s'arr√™te plus t√¥t. La page est donc skip mais reste manquante jusqu'√† que les cr√©ateurs du site r√©pare le probl√®me
- De temps en temps, suite au scrapping, le graphique r√©pr√©sentant les notes dans la partie analyse est totalement incoh√©rent (affichant 400 notes √† 12 et 12.5 et rien d'autres)

Si vous rencontrez d'autres bugs n'hesitez pas √† nous contacter. 

<p align="center">(<a href="#readme-top">Haut de la page</a>)</p>

**Owen et Elliot**

*Notre recette : un projet bien √©pic√©, une pinc√©e de code, et beaucoup de passion. üßë‚Äçüç≥üíª*

*Bonne correction et merci pour votre temps ! üòä*

<p align="center">(<a href="#readme-top">Haut de la page</a>)</p>

