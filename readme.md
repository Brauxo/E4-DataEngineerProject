![Static Badge](https://img.shields.io/badge/ESIEE%20Paris%20-%20Projet%20E4%20-%20green?style=flat)
![Static Badge](https://img.shields.io/badge/last%20commit%20-%20November%202024%20-%20blue)
<div align="center">
<img src="https://github.com/user-attachments/assets/78cac6dc-d058-4576-8eef-572581c74311" width="65%"/>
</div>
<a id="readme-top"></a>

# Description

Ce projet vise √† extraire des donn√©es depuis le site 'gaultmillau.com', les stocker dans une base de donn√©es Elasticsearch, et les rendre consultables √† travers une application Web cr√©√©e avec Flask.
Pour offrir une exp√©rience utilisateur fluide, nous avons utilis√© Elasticsearch pour optimiser les capacit√©s de recherche et con√ßu une interface interactive en combinant CSS et JavaScript. Le projet s‚Äôappuie sur Docker pour simplifier le d√©ploiement, automatiser l‚Äôex√©cution des diff√©rentes √©tapes (scraping, stockage, service Web) et garantir une reproductibilit√© optimale sur diff√©rents environnements.

<a id="readme-top"></a>
# Sommaire

## Guide de l'utilisateur
1. [Pr√©requis d'installation](#1---Pr√©requis-dinstallation)
2. [Installation](#2---Installation)
3. [Lancer le projet](#3---Lancer-le-projet)
4. [Les diff√©rentes pages](#4---Les-differentes-pages)

## Guide du D√©veloppeur
1. [Aper√ßu global du projet](#1---Aper√ßu-global-du-projet)
2. [Scraping](#2---Scraping)
3. [API Web](#3---API-Web)
4. [Architecture et technologies utilis√©es](#4---Architecture-et-technologies-utilis√©es)

## Pour aller plus loin
1. [Id√©es d'am√©liorations](#1---Id√©es-dam√©liorations)
2. [D√©fis rencontr√©s](#2---D√©fis-rencontr√©s)
3. [Bugs connus](#3---Bugs-connus)


# Guide de l'utilisateur

## 1 - Pr√©requis d'installation

Dans un premier temps, regardons ce que vous devez installer pour r√©cup√©rer et utiliser le projet.

Deux outils sont n√©cessaires :

[Git](https://github.com/cambierelliot/E4-DataEngineerProject) pour cloner le projet depuis le d√©p√¥t opensource GitHub.

[DockerDesktop](https://www.docker.com/products/docker-desktop/) pour faire fonctionner le projet.

Faites une installation classique de docker.

## 2 - Installation

Dans cette partie, nous allons importer le projet disponible sur GitHub afin de l‚Äôavoir sur votre machine (en local).

Pour ce faire, ouvrez le Git Bash ou tout autre terminal et rendez-vous dans le dossier o√π vous d√©sirez stocker le projet gr√¢ce √† la commande :
```
   $ cd <r√©pertoire d√©sir√©>/
```
Lorsque vous √™tes dans le dossier voulu, rentrez la commande suivante :
```
   $ git clone https://github.com/cambiere/E4-DataEngineerProject
```
‚ö† Attendez l'importation totale du projet

## 3 - Lancer le projet

Commencez par rejoindre le dossier du projet :

```
   $ cd E4-DataEngineerProject/
```
Une fois que vous √™tes bien dans ce r√©pertoire, veuillez lancer l'application docker (e.g. DockerDesktop sur Windows). Elle doit √™tre en fonctionnement pour continuer.

Pour ex√©cuter le projet, il suffit de rentrer la commande suivante
```
$ docker compose up -d
```


Patientez jusqu'√† l'apparition d'un groupe de conteneurs dans votre application Docker. Cela peut prendre quelques minutes, car le processus de scraping est en cours. Un volume est √©galement cr√©√© pour les lancements ult√©rieurs : le scraping ne sera alors plus n√©cessaire, et les donn√©es locales seront utilis√©es.

‚ö† Veillez √† ne pas arr√™ter les services pour le bon fonctionnement de l'application Web.

Une fois le service flask en vert, vous pouvez cliquer sur le port surlign√© en jaune 5000 :5000 (voir image ci-dessous) ou bien cliquer ici : http://localhost:5000/
![image](https://github.com/user-attachments/assets/aa1cdcf7-a114-42f7-8e11-be71561aa07e)

<p align="center">(<a href="#readme-top">Haut de la page</a>)</p>

## 4 - Les diff√©rentes pages

<div align="center">
<h3>Page d'accueil du site</h3>
</div>

![home](img/home.gif)

La page d'accueil du site pr√©sente un design √©l√©gant et intuitif, permettant aux utilisateurs de rechercher et d√©couvrir des restaurants selon leurs pr√©f√©rences. Voici les principales caract√©ristiques de cette page :

#### Barre de recherche personnalis√©e
- Trois menus d√©roulants pour affiner les crit√®res de recherche :
  - **D√©partement** : Permet de s√©lectionner une r√©gion g√©ographique.
  - **Type de cuisine** : Offre des options comme "Fran√ßais", "Italien", "Japonais", etc.
  - **Note minimale** : Permet de filtrer les restaurants en fonction de leur score.
- Un bouton **"Rechercher"** pour effectuer la recherche selon les crit√®res s√©lectionn√©s.

#### Navigation rapide par types de cuisine
- Une section en dessous de la barre de recherche met en avant **6 types de cuisine populaires**.
- Chaque cat√©gorie est **cliquable** et redirige l'utilisateur vers une page d√©di√©e pour explorer des restaurants sp√©cifiques.

#### Header interactif
- Un header fixe contenant des liens vers les sections principales du site :
  - **Les restaurants**
  - **Analyse**
  - **√Ä propos de nous**
- Le header dispara√Æt automatiquement lors du d√©filement vers le bas pour laisser plus d'espace √† l'utilisateur et r√©appara√Æt en haut.

#### Footer informatif
- Le footer inclut des liens suppl√©mentaires, des informations sur les auteurs du projet et un design sobre pour cl√¥turer la page.

<div align="center">
<h3> Page exploration restaurant </h3>
</div>

![resto.gif](img/resto.gif)
La page est d√©di√©e √† la recherche et √† l'exploration de restaurants. Les principaux composants de la page :

#### Filtres de Recherche de Restaurants
Les utilisateurs peuvent filtrer les restaurants selon plusieurs crit√®res :
- **Curseur de Note** : Un curseur permet de d√©finir une note minimale pour les restaurants recherch√©s.
- **Menu D√©roulant D√©partement** : Un menu d√©roulant permet aux utilisateurs de s√©lectionner un d√©partement sp√©cifique en France pour affiner la recherche.
- **Cases √† Cocher Types de Cuisine** : Un menu d√©roulant avec des cases √† cocher permet aux utilisateurs de s√©lectionner un ou plusieurs types de cuisine (par exemple, Fran√ßais, Italien, Japonais).
- **Bouton de Recherche** : Un bouton est disponible pour lancer la recherche selon les filtres s√©lectionn√©s.
- **Affichage des R√©sultats** : La page affiche le nombre de restaurants correspondant aux crit√®res et propose un bouton pour r√©initialiser les filtres.

#### Liste des Restaurants
Les restaurants sont affich√©s sous forme de liste, chacun comprenant :
- **Image** : Une image du restaurant avec sa cat√©gorie.
- **Nom et Note** : Le nom et la note du restaurant.
- **Informations Suppl√©mentaires** : Des d√©tails tels que le nom du chef, le type(s) de cuisine, le budget et l'adresse.

#### Pagination
La liste des restaurants est pagin√©e, et les utilisateurs peuvent naviguer entre plusieurs pages de r√©sultats gr√¢ce aux boutons "pr√©c√©dent" et "suivant", ainsi qu'aux liens des num√©ros de pages.


<div align="center">
<h3> Page d'analyse </h3>
</div>

<div align="center">
<h3> Page a propos de nous </h3>
</div>

![home](img/about.gif)
La page "√Ä propos de nous" pr√©sente les contributeurs principaux du projet avec leurs profils respectifs et les outils utilis√©s dans le d√©veloppement du site.

- **Pr√©sentation des contributeurs** : Chaque contributeur est affich√© avec une photo, un descriptif de son parcours, et ses domaines d'expertise.
- **Contact direct** : Les adresses email des contributeurs sont fournies pour toute communication.
- **Technologies utilis√©es** : Une section en bas met en avant les principaux outils et technologies comme Elasticsearch, Docker, Scrapy, GitHub, et Flask.

<p align="center">(<a href="#readme-top">Haut de la page</a>)</p>

# Guide du D√©veloppeur

## 1 - Aper√ßu global
Le projet propose une solution int√©gr√©e permettant de scrapper les donn√©es de restaurants depuis **Gault & Millau**, de les stocker dans **MongoDb** et **Elasticsearch**, et de les rendre accessibles via une application web construite avec **Flask**. L'architecture repose sur Docker pour assurer un d√©ploiement reproductible.

## 2 - Scrapping
Le projet utilise **Scrapy** pour effectuer le scraping des donn√©es disponibles sur le site Gault&Millau.

Il fonctionne de la mani√®re suivante : 
1. Le scraper navigue sur les pages du site Gault&Millau en suivant une logique de pagination.
2. Il extrait les informations pertinentes pour chaque restaurant, telles que :
   - Nom,
   - Adresse,
   - Chef,
   - Sp√©cialit√© culinaire,
   - Note (ou cat√©gorie sp√©ciale comme "Membre de l'Acad√©mie Gault&Millau"),
   - Budget,
   - URL du restaurant,
   - Photo.
3. Les donn√©es extraites sont stock√©es sous forme d'objets d√©finis par le fichier `items.py`.

## 3 - API Web
Le backend, bas√© sur **Flask**, offre des endpoints pour :
- Afficher la liste des restaurants.
- Obtenir des d√©tails sp√©cifiques √† un restaurant.
- Rechercher par mot-cl√© ou crit√®res (ex. sp√©cialit√©, localisation).

N'ayant jamais utilis√© **Flask** auparavant, nous avons suivi des tutoriels pour apprendre les bases et d√©velopper notre API, notamment la s√©rie de cours disponible ici : [Tutoriel Flask sur YouTube](https://www.youtube.com/watch?v=o3bCVqF9gI0&list=PL7yh-TELLS1EyAye_UMnlsTGKxg8uatkM).

L'un d'entre nous avait d√©j√† acquis des comp√©tences en **HTML**, **CSS** et **JavaScript** lors d'un stage d'un mois effectu√© pendant l'√©t√©, ce qui a facilit√© le d√©veloppement de la partie frontend de notre projet.

Flask repose sur le principe des **routes**, qui d√©finissent les points d'acc√®s √† notre application web. Le fichier principal, `app.py`, joue le r√¥le de c≈ìur de l'application et redirige les requ√™tes vers des pages sp√©cifiques, comme `restaurant.html` dans notre cas.

Par exemple, dans la capture ci-dessous, on voit une route d√©finie avec le d√©corateur `@app.route("/restaurant")`. Cette route est charg√©e de :

1. **R√©cup√©rer les param√®tres** de la requ√™te (comme `min_rating`, `department` et `cuisine`).
2. **Construire une requ√™te Elasticsearch** pour filtrer les restaurants.
3. **Envoyer les donn√©es filtr√©es** √† la page HTML via `render_template()`.

La page **HTML**, ici `restaurant.html`, re√ßoit les donn√©es renvoy√©es par Flask (comme la liste des restaurants, les d√©partements uniques et les types de cuisines) pour les afficher dynamiquement sur le frontend.

Ce d√©coupage entre le fichier principal `app.py` (backend) et les fichiers **HTML** (frontend) permet une architecture claire et modulaire. Chaque route dans Flask peut g√©rer des logiques sp√©cifiques et renvoyer des r√©sultats adapt√©s √† la page correspondante.

<div align="center">
<img src="img/code.png" width="55%"/>
</div>

## 4 - Architecture et technologies utilis√©es
- **Backend** : Python, Flask.
- **Scraping** : Scrapy
- **Base de donn√©es** : Elasticsearch, MongoDB.
- **Frontend** : HTML/CSS/JS.
- **D√©ploiement** : Docker Compose.

**Pourquoi avons-nous choisit ces technologies ?** 

Nous avons opt√© pour **MongoDB** et **Elasticsearch** en raison de leur flexibilit√© dans la gestion des objets et de leur simplicit√© d'utilisation. Ces bases de donn√©es permettent une int√©gration rapide des donn√©es tout en offrant des performances √©lev√©es pour la recherche et l'analyse.

Concernant le backend, nous avons choisi **Flask** afin d'explorer une alternative √† Dash, utilis√© dans un pr√©c√©dent projet lors de la p√©riode 1. Flask s'est r√©v√©l√© √™tre un choix pertinent gr√¢ce √† sa prise en main facile, sa l√©g√®ret√© et ses nombreuses fonctionnalit√©s qui facilitent le d√©veloppement d'API et d'applications web.

Enfin, l'utilisation de **Docker Compose** permet de simplifier le d√©ploiement et l'orchestration des diff√©rents composants de notre architecture, assurant ainsi une solution coh√©rente et facilement r√©plicable.

#### Architecture simplifi√©e de notre application web
![archi.png](img/archi.png)

#### Architecture global du projet
Nous avons segment√© notre code en plusieurs dossiers afin de le rendre plus facilement compr√©hensible. Deux dossiers principaux structurent notre projet : 

1. **`Api_WEB`** : Ce dossier g√®re tout ce qui concerne l'application Flask.
2. **`gaultmillau_scraper`** : Ce dossier s'occupe de l'ensemble de la phase de scraping effectu√©e en amont.

Avantages de cette Architecture : 
- **Modularit√©** : Lors du d√©veloppement, il n'est pas n√©cessaire de pousser l'int√©gralit√© du projet sur le d√©p√¥t, mais uniquement les branches modifi√©es, ce qui simplifie la gestion des versions.
- **Lisibilit√©** : La s√©paration claire des responsabilit√©s facilite la compr√©hension et le travail collaboratif sur le projet.


<div align="center">
<img src="img/archicomplet.png" width="45%"/>
</div>

<p align="center">(<a href="#readme-top">Haut de la page</a>)</p>

# Pour aller plus loin

## 1 - Id√©es d'am√©liorations
- Ajouter des **filtres dynamiques** (par budget, distance).
- Int√©grer une **interface mobile-friendly** ou cr√©er une app mobile.
- Mettre en place une **API REST avanc√©e** pour d‚Äôautres types de clients (apps tierces).

## 2 - D√©fis rencontr√©s
- Contournement des **limitations des sites web** (CAPTCHA, restrictions IP).
- Optimisation des requ√™tes Elasticsearch.
- Assurer une **compatibilit√© front-end** entre navigateurs.

## 3 - Bugs connus
- [en partie r√©solu] Il se peut qu'une des pages du site de gault et millau soit down et que le scrapping s'arr√™te plus t√¥t. La page est donc skip mais reste manquante jusqu'√† que les cr√©ateurs du site r√©pare le probl√®me
- De temps en temps, suite au scrapping, le graphique r√©pr√©sentant les notes dans la partie analyse est totalement incoh√©rent (affichant 400 notes √† 12 et 12.5 et rien d'autres)

Si vous rencontrez d'autres bugs n'hesitez pas √† nous contacter. 

<p align="center">(<a href="#readme-top">Haut de la page</a>)</p>

**Owen et Elliot**

*Notre recette : un projet bien √©pic√©, une pinc√©e de code, et beaucoup de passion. üßë‚Äçüç≥üíª*

*Bonne correction et merci pour votre temps ! üòä*

<p align="center">(<a href="#readme-top">Haut de la page</a>)</p>

